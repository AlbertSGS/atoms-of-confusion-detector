# Atoms of Confusion Detector

This is a tool for detecting atoms of confusion in the Java language as showcased in
this [paper](https://arxiv.org/pdf/2103.05424.pdf) by Langhout and Aniche.

## How to use

## Implementation

In this section you can find information about the implementation of the different parts of the tool. For more details,
feel free to also check the documentation of the classes and the methods in the source code.

### Input

The tool accepts user commands through the command line. To parse this commands we have used
the [CLIKT](https://ajalt.github.io/clikt/) library.

For the actual input, i.e the source code to be analysed, the tool can either use local files and directories or get it
from GitHub Pull Requests.

In terms of code the different sources of input are encoded by the classes found in the `InputSource.kt` file under
the `input` package. In the same package you can find the `InputParser` class which is used to parse individual files
and also all files in a directory (recursively). In that package you can also find all the classes responsible for the
parsing of the command line arguments.

#### Resolving Pull Requests

### Analysis

Here you can find high-level descriptions of the different parts of the analysis pipeline of the tool.

#### Parsing

To parse the code the tool uses a parser generated using [ANTLR v4](https://www.antlr.org/). The grammar we used, as
well as the generated parser and lexer can be found under `src/main/java`.

#### Detecting Atoms of Confusion

To detect the atoms in the code the listener infrastructure provided by ANTLR has been heavily utilized. Using this we
implemented the `AtomsListener` class, which can be found under the `parsing` package in the code base. This listener is
responsible for traversing the parse tree generated by the parser. During the traversal the listener can pass certain
nodes of the tree to different **Detectors** to check for atoms.

Detectors are the classes responsible for actually analysing a part of the source code for atoms. In general each
detector corresponds to one specific atom. All Detectors can be found in the `parsing.detectors` package. Each detector
is annotated with the `Visit` annotation which specifies on what nodes of the parse tree this detector should be called.
Then the detectors are registered to the `AtomsListener` who uses the annotation to know when to call a specific
detector.

#### Scoping

To detect some of the atoms, identifier and symbol resolution was required. That is why the tool also keeps scoping
information on the code that's being analysed. To implement this we have extended
the [symtab](https://github.com/antlr/symtab)
library provided by the Antlr team. The classes that we have added to extend the library's functionality can be found
under the `parsing.symtab` package. The logic related with scoping is implemented by the `AtomsListener`.

### Output

In this section you can find information on how the tool internally represents the results of the analysis as well as to
how the tool outputs them.

#### The Confusion Graph

The confusion graph is a specialised data structure developed for the purposes of this tool that allows for quickly
storing the atoms found as well for efficient queries. The main idea behind it is that there are 2 different types of
nodes (Atoms nodes representing a type of atom and Source nodes representing an input file) and they are connected to
each other with edges that include information about where the atom appears. For example if we have file `Hello.java` in
which the `Type Conversion` atom exists on lines 10, 32 and 50 then in the graph we would have the `Type Conversion`
atom node connected to the `Hello.java` source node with an edge containing the set `{10, 32, 50}`. Keep in mind that
Atom nodes can only be connected to Source nodes and vice versa. This constraint is enforced by the code and exceptions
will arise if you try to connect 2 nodes of the same type. One last thing to add, is that due to the implementation of
the graph which is based on hash maps and some duplication of information most operations are of `O(1)` complexity. This
allows the tool to remain fast even when analysing large sets of files. The code of the graph can be found in
the `output.graph` package.

#### Pull Request Deltas

The tool also provides support for seeing how atoms have changed between pull requests. This is implemented in two
steps. Firstly the `diff` file associated with the pull request to get information about which lines have been removed
and added. This is implemented by the `DiffParser` class found in the `github` package. Secondly, the information
retrieved is compared with the information in the graphs generated by analysing the "from" and "to" branches of the pull
request to see what atoms have been removed, added and remain. The logic for this is implemented in the `PRDelta` class
under the aforementioned package.

#### Writing the output

Finally, to write the output to CSV files we have used the [kotlin-csv](https://github.com/doyaaaaaken/kotlin-csv)
library to implement the `CsvWriter` which provides methods for writing both the csv graph and the PRDelta to CSV files.
The code for this class can be found in the `output.writers` package. 